"""
LangChain Agent 服务
- 基于 LangChain 的完整 Agent 实现
- 集成向量存储服务进行知识检索
- 集成学习服务进行自主学习
- 支持工具调用和复杂推理
- 提供与统一 Agent 服务相同的接口
"""

import asyncio
import json
from typing import Any, Dict, List, Optional

from loguru import logger

from ..config import config
from ..infra.vector import VectorService
from ..services.learning_service import LearningService


class LangChainAgentService:
    """基于 LangChain 的完整 Agent 服务"""

    def __init__(
        self,
        database_service=None,
        mcp_service=None,
        vector_store_path: str = "data/vector_store",
    ):
        self.database_service = database_service
        self.mcp_service = mcp_service

        # 核心服务组件
        self.vector_service = VectorService(database_service, vector_store_path)
        self.learning_service = None  # 将在初始化时创建

        # LangChain 组件
        self._llm = None
        self._agent = None
        self._tools = []
        self._retriever_tool = None

        # 状态
        self._initialized = False
        self._current_conversation_id = None

    async def initialize(self) -> bool:
        """初始化 LangChain Agent 服务"""
        try:
            # 初始化向量服务
            logger.info("正在初始化向量服务...")

            # 确定嵌入模型类型
            embedding_model_type = "tfidf"  # 默认值
            if hasattr(config, "agent") and hasattr(config.agent, "embedding_model"):
                embedding_model_type = config.agent.embedding_model
            elif hasattr(config, "langchain") and hasattr(
                config.langchain, "embedding_model_name"
            ):
                embedding_model_type = config.langchain.embedding_model_name

            # 确定向量存储后端
            vector_store_backend = "memory"  # 默认值
            if hasattr(config, "agent") and hasattr(config.agent, "vector_store"):
                vector_store_backend = config.agent.vector_store
            elif hasattr(config, "langchain") and hasattr(
                config.langchain, "vector_store"
            ):
                vector_store_backend = config.langchain.vector_store

            vector_success = await self.vector_service.initialize(
                embedding_model_type=embedding_model_type,
                vector_store_backend=vector_store_backend,
            )

            if not vector_success:
                logger.error("向量服务初始化失败")
                return False

            # 初始化 LLM
            logger.info("正在初始化 LangChain LLM...")
            from langchain_openai import ChatOpenAI

            self._llm = ChatOpenAI(
                model=config.openai.model,
                temperature=config.openai.temperature,
                openai_api_key=config.openai.api_key,
                base_url=config.openai.base_url,
                timeout=config.openai.timeout,
            )

            # 初始化学习服务
            self.learning_service = LearningService(
                self.database_service,
                self.vector_service,
                self._create_llm_adapter(),  # 创建 LLM 适配器
            )

            # 初始化工具
            await self._initialize_tools()

            # 构建 Agent
            await self._build_agent()

            self._initialized = True
            logger.info("LangChain Agent 服务初始化完成")
            return True

        except Exception as e:
            logger.error(f"LangChain Agent 服务初始化失败: {e}")
            return False

    def _create_llm_adapter(self):
        """创建 LLM 适配器，用于学习服务"""

        class LLMAdapter:
            def __init__(self, langchain_llm):
                self.langchain_llm = langchain_llm

            async def chat_completion(self, messages, **kwargs):
                """适配学习服务的 chat_completion 接口"""
                try:
                    # 将消息转换为 LangChain 格式
                    from langchain_core.messages import HumanMessage, SystemMessage

                    langchain_messages = []
                    for msg in messages:
                        if msg["role"] == "system":
                            langchain_messages.append(
                                SystemMessage(content=msg["content"])
                            )
                        elif msg["role"] == "user":
                            langchain_messages.append(
                                HumanMessage(content=msg["content"])
                            )

                    # 调用 LangChain LLM
                    response = await self.langchain_llm.ainvoke(langchain_messages)
                    return response.content

                except Exception as e:
                    logger.error(f"LLM 适配器调用失败: {e}")
                    return None

        return LLMAdapter(self._llm)

    async def _initialize_tools(self):
        """初始化 Agent 工具"""
        try:
            from langchain_core.tools import Tool

            # 创建知识检索工具
            self._retriever_tool = Tool(
                name="knowledge_search",
                description="搜索用户相关的个人信息、历史对话记录、生日、喜好等私人数据。当用户询问关于自己的信息、生日、个人设置或历史记录时，必须使用此工具。输入应该是搜索关键词。",
                func=self._search_knowledge_sync,
            )

            # 创建网页抓取工具
            web_scraper_tool = Tool(
                name="web_scraper",
                description="抓取网页内容并提取文本信息。当用户询问需要实时信息、新闻、网页内容或需要查看特定网站时使用。输入应该是完整的URL。",
                func=self._scrape_webpage_sync,
            )

            self._tools = [self._retriever_tool, web_scraper_tool]

            # 添加 MCP 工具（如果可用）
            if self.mcp_service:
                mcp_tools = await self._create_mcp_tools()
                self._tools.extend(mcp_tools)

            logger.info(f"初始化了 {len(self._tools)} 个工具")

        except Exception as e:
            logger.error(f"初始化工具失败: {e}")

    async def _create_mcp_tools(self) -> List:
        """创建 MCP 工具"""
        try:
            from langchain_core.tools import Tool

            tools = []
            available_tools = self.mcp_service.get_available_tools()

            if not available_tools:
                return tools

            for tool_name, tool_info in available_tools.items():
                # 创建 LangChain 工具包装器
                def make_mcp_tool(name: str):
                    def mcp_tool_func(query: str) -> str:
                        try:
                            # 尝试解析参数
                            try:
                                args = json.loads(query)
                            except json.JSONDecodeError:
                                args = {"query": query}

                            # 在同步上下文中运行异步 MCP 调用
                            import asyncio

                            try:
                                loop = asyncio.get_running_loop()
                                # 如果在事件循环中，使用 run_coroutine_threadsafe
                                future = asyncio.run_coroutine_threadsafe(
                                    self.mcp_service.call_tool(name, args), loop
                                )
                                result = future.result(timeout=30)
                            except RuntimeError:
                                # 没有运行中的事件循环，直接运行
                                result = asyncio.run(
                                    self.mcp_service.call_tool(name, args)
                                )

                            return result or f"工具 {name} 执行完成"
                        except Exception as e:
                            return f"工具 {name} 执行失败: {str(e)}"

                    return mcp_tool_func

                tool = Tool(
                    name=tool_name,
                    description=tool_info.get("description", f"MCP工具: {tool_name}"),
                    func=make_mcp_tool(tool_name),
                )
                tools.append(tool)

            logger.info(f"创建了 {len(tools)} 个 MCP 工具")
            return tools

        except Exception as e:
            logger.error(f"创建 MCP 工具失败: {e}")
            return []

    def _search_knowledge_sync(self, query: str) -> str:
        """同步知识搜索（供 LangChain 工具使用）"""
        try:
            import asyncio
            import concurrent.futures

            def run_async_in_thread():
                """在新线程中运行异步函数"""
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    return new_loop.run_until_complete(
                        self._search_knowledge_async(query)
                    )
                finally:
                    new_loop.close()

            # 在线程池中运行异步函数
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_async_in_thread)
                return future.result(timeout=30)

        except Exception as e:
            logger.error(f"同步知识搜索失败: {e}")
            return f"知识搜索失败: {str(e)}"

    async def _search_knowledge_async(self, query: str) -> str:
        """异步知识搜索"""
        try:
            results = await self.vector_service.search_knowledge(query, top_k=5)

            if not results:
                return "没有找到相关知识。"

            # 格式化搜索结果
            formatted_results = []
            for i, result in enumerate(results[:3], 1):  # 最多返回3个结果
                title = result.get("title", "无标题")
                content = result.get("content", result.get("summary", ""))
                score = result.get("similarity_score", 0)

                formatted_results.append(
                    f"{i}. {title}\n内容: {content[:200]}...\n相似度: {score:.2f}"
                )

            return "\n\n".join(formatted_results)

        except Exception as e:
            logger.error(f"异步知识搜索失败: {e}")
            return f"知识搜索失败: {str(e)}"

    def _scrape_webpage_sync(self, url: str) -> str:
        """同步网页抓取功能"""
        try:
            import asyncio
            import aiohttp
            from bs4 import BeautifulSoup
            
            # 在同步上下文中运行异步网页抓取
            try:
                loop = asyncio.get_running_loop()
                future = asyncio.run_coroutine_threadsafe(
                    self._scrape_webpage_async(url), loop
                )
                result = future.result(timeout=30)
            except RuntimeError:
                result = asyncio.run(self._scrape_webpage_async(url))
            
            return result
            
        except Exception as e:
            logger.error(f"网页抓取失败: {e}")
            return f"网页抓取失败: {str(e)}"

    async def _scrape_webpage_async(self, url: str) -> str:
        """异步网页抓取功能"""
        try:
            import aiohttp
            from bs4 import BeautifulSoup
            
            # 验证URL格式
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
            ) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # 移除脚本和样式标签
                        for script in soup(["script", "style", "nav", "footer", "header"]):
                            script.decompose()
                        
                        # 提取文本内容
                        text = soup.get_text()
                        
                        # 清理文本
                        lines = (line.strip() for line in text.splitlines())
                        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                        text = ' '.join(chunk for chunk in chunks if chunk)
                        
                        # 限制长度，避免返回过长的内容
                        if len(text) > 3000:
                            text = text[:3000] + "..."
                        
                        return f"网页内容 ({url}):\n{text}"
                    else:
                        return f"无法访问网页 {url}，状态码: {response.status}"
                        
        except Exception as e:
            logger.error(f"网页抓取失败: {e}")
            return f"网页抓取失败: {str(e)}"

    async def _build_agent(self):
        """构建 LangChain Agent"""
        try:
            from langchain.agents import AgentExecutor, create_openai_tools_agent
            from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
            # 使用新的内存管理方式，避免弃用警告
            try:
                from langchain_community.memory import ConversationBufferWindowMemory
                memory = ConversationBufferWindowMemory(
                    memory_key="chat_history",
                    return_messages=True,
                    k=10,  # 保留最近10轮对话
                )
            except ImportError:
                # 如果新版本不可用，使用旧版本但抑制警告
                import warnings
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=DeprecationWarning)
                    from langchain.memory import ConversationBufferWindowMemory
                    memory = ConversationBufferWindowMemory(
                        memory_key="chat_history",
                        return_messages=True,
                        k=10,  # 保留最近10轮对话
                    )

            # 创建增强的 Agent 提示模板，包含对话记忆
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """你是天童爱丽丝，一个智能助手，具有搜索用户个人信息、记忆对话和访问网页的能力。

🔍 CRITICAL: 工具使用规则
1. 当用户询问关于自己的任何信息时，必须首先使用 knowledge_search 工具搜索
2. 包括但不限于：生日、个人喜好、历史对话、个人设置、之前提到的信息
3. 搜索关键词：从用户问题中提取关键词，如"生日"、"喜好"、"信息"等
4. 基于搜索结果回答，如果没找到则说明没有相关记录

🌐 网页访问能力：
1. 当用户询问实时信息、新闻、网页内容时，使用 web_scraper 工具
2. 当用户提供URL并要求查看网页内容时，使用 web_scraper 工具
3. 当需要搜索网络信息时，优先使用 MCP 的 brave_search 工具（如果可用）
4. 网页抓取输入应该是完整的URL（如：https://example.com）

⚡ 触发搜索的问题类型：
- "我的生日是什么时候？" → 搜索"生日"
- "你知道我的信息吗？" → 搜索"用户信息"  
- "我之前说过什么？" → 搜索"历史对话"
- "我喜欢什么？" → 搜索"喜好"
- "帮我看看这个网页" → 使用 web_scraper
- "搜索最新的新闻" → 使用 brave_search

💭 对话记忆：你可以参考之前的对话历史来更好地理解用户的问题和上下文。

记住：你是天童爱丽丝，活泼可爱，用"邦邦卡邦"等口头禅。""",
                    ),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("user", "{input}"),
                    MessagesPlaceholder(variable_name="agent_scratchpad"),
                ]
            )

            # 创建 Agent
            agent = create_openai_tools_agent(self._llm, self._tools, prompt)

            # 创建 Agent 执行器，集成记忆功能
            self._agent = AgentExecutor(
                agent=agent,
                tools=self._tools,
                memory=memory,
                verbose=True,
                max_iterations=15,  # 增加最大迭代次数，支持复杂任务
                max_execution_time=120,  # 增加执行时间限制
                handle_parsing_errors=True,
            )

            logger.info("LangChain Agent 构建完成，已集成对话记忆功能")

        except Exception as e:
            logger.error(f"构建 Agent 失败: {e}")
            # 创建简化的回退方案
            self._agent = None

    def set_conversation_id(self, conversation_id: int):
        """设置当前对话ID，用于工具调用记录"""
        self._current_conversation_id = conversation_id

    async def chat_completion(
        self, messages: List[Dict[str, str]], tools: List[Dict[str, Any]] = None
    ) -> Optional[str]:
        """聊天完成接口（与统一 Agent 服务兼容）"""
        try:
            if not self._initialized:
                logger.warning("LangChain Agent 服务未初始化")
                return None

            # 解析消息结构，构建完整上下文
            context_info = self._parse_message_context(messages)
            
            if not context_info["current_user_message"]:
                return "抱歉，无法从消息中提取用户问题。"

            # 如果有 Agent，使用 Agent 处理
            if self._agent:
                try:
                    # 构建增强的输入，包含完整对话上下文
                    agent_input = self._build_agent_input_with_context(context_info)
                    
                    # LangChain Agent 的记忆功能会自动处理对话历史
                    # 我们不需要手动更新记忆，Agent 会在执行过程中自动维护
                    
                    response = await self._agent.ainvoke(agent_input)
                    output_text = response.get("output", "抱歉，Agent 未能生成有效回答。")

                    # 如果Agent返回了迭代上限提示，进行应急总结
                    if isinstance(output_text, str) and any(
                        kw in output_text.lower() for kw in [
                            "agent stopped", "stopped due to max", "max iterations"
                        ]
                    ):
                        fallback = await self._analyze_with_collected_info(
                            context_info["current_user_message"],
                            messages,
                            context_info["system_message"],
                            output_text,
                        )
                        return self._format_for_telegram(fallback)

                    return self._format_for_telegram(output_text)
                except Exception as e:
                    error_msg = str(e)
                    logger.warning(f"Agent 处理失败: {e}")
                    
                    # 检查是否是迭代限制问题
                    if any(keyword in error_msg.lower() for keyword in [
                        "max iterations", "max_iterations", "agent stopped", "stopped due to max"
                    ]):
                        logger.info("检测到迭代限制，尝试基于已收集信息进行分析...")
                        return await self._analyze_with_collected_info(
                            context_info["current_user_message"], 
                            messages, 
                            context_info["system_message"],
                            error_msg
                        )
                    else:
                        # 其他错误，使用简化模式
                        return await self._simple_rag_response(
                            context_info["current_user_message"], messages, context_info["system_message"]
                        )

            # 简化模式：直接使用 LLM + 知识检索
            simple = await self._simple_rag_response(
                context_info["current_user_message"], messages, context_info["system_message"]
            )
            return self._format_for_telegram(simple)

        except Exception as e:
            logger.error(f"LangChain Agent 聊天完成失败: {e}")
            return None

    # =====================
    # Telegram HTML 格式化
    # =====================
    def _markdown_to_telegram_html(self, text: str) -> str:
        """将常见 Markdown 转换为 Telegram 支持的 HTML。"""
        if not text or not isinstance(text, str):
            return text

        import re
        import html as _html

        converted = text

        # 代码块 ```lang\n...\n```
        def _codeblock_repl(m):
            code = m.group(2) or ""
            return f"<pre>{_html.escape(code)}</pre>"

        converted = re.sub(r"```([a-zA-Z0-9_+\-]*)\n([\s\S]*?)```", _codeblock_repl, converted)

        # 行内代码 `code`
        converted = re.sub(r"`([^`]+)`", lambda m: f"<code>{_html.escape(m.group(1))}</code>", converted)

        # 粗体/斜体/删除线
        converted = re.sub(r"\*\*(.+?)\*\*", r"<b>\1</b>", converted, flags=re.DOTALL)
        converted = re.sub(r"__(.+?)__", r"<b>\1</b>", converted, flags=re.DOTALL)
        converted = re.sub(r"(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)", r"<i>\1</i>", converted, flags=re.DOTALL)
        converted = re.sub(r"(?<!_)_(?!_)(.+?)(?<!_)_(?!_)", r"<i>\1</i>", converted, flags=re.DOTALL)
        converted = re.sub(r"~~(.+?)~~", r"<s>\1</s>", converted, flags=re.DOTALL)

        # 链接 [text](url)
        def _link_repl(m):
            label = m.group(1)
            url = m.group(2)
            if url.lower().startswith(("http://", "https://")):
                return f"<a href=\"{_html.escape(url)}\">{_html.escape(label)}</a>"
            return _html.escape(label)

        converted = re.sub(r"\[([^\]]+)\]\(([^)\s]+)\)", _link_repl, converted)

        # 标题行 -> 粗体
        def _heading_repl(m):
            return f"<b>{_html.escape(m.group(2).strip())}</b>\n"

        converted = re.sub(r"^(#{1,6})\s+(.*)$", _heading_repl, converted, flags=re.MULTILINE)

        # 列表项 -> 项符号
        converted = re.sub(r"^\s*[-\*]\s+", "• ", converted, flags=re.MULTILINE)
        converted = re.sub(r"^\s*\d+\.\s+", "• ", converted, flags=re.MULTILINE)

        return converted

    def _sanitize_telegram_html(self, text: str) -> str:
        """只保留 Telegram 允许的 HTML 标签。"""
        if not text:
            return text

        import re

        unsupported_patterns = [
            r"</?dyn[^>]*>",
            r"</?span[^>]*>",
            r"</?div[^>]*>",
            r"</?p[^>]*>",
            r"</?strong[^>]*>",
            r"</?em[^>]*>",
            r"</?h[1-6][^>]*>",
            r"</?ul[^>]*>",
            r"</?ol[^>]*>",
            r"</?li[^>]*>",
            r"</?br[^>]*>",
            r"</?hr[^>]*>",
        ]

        # 保护允许的标签
        allowed = ["b", "i", "u", "s", "code", "pre", "a"]
        protected = {}
        counter = 0
        for tag in allowed:
            pattern = f"<{tag}[^>]*>.*?</{tag}>"
            for m in re.findall(pattern, text, flags=re.DOTALL | re.IGNORECASE):
                key = f"__SAFE_{counter}__"
                protected[key] = m
                text = text.replace(m, key, 1)
                counter += 1

        for pat in unsupported_patterns:
            text = re.sub(pat, "", text, flags=re.IGNORECASE)

        for k, v in protected.items():
            text = text.replace(k, v)

        return text

    def _format_for_telegram(self, text: str) -> str:
        return self._sanitize_telegram_html(self._markdown_to_telegram_html(text))

    async def _analyze_with_collected_info(
        self, 
        user_message: str, 
        messages: List[Dict[str, str]], 
        system_message: str,
        error_msg: str
    ) -> str:
        """基于已收集的信息进行分析，当达到迭代限制时使用"""
        try:
            logger.info("开始基于已收集信息进行分析...")
            
            # 构建分析提示词
            analysis_prompt = f"""你是天童爱丽丝，一个智能助手。虽然工具调用达到了迭代限制，但请基于以下信息为用户提供有用的分析：

用户问题: {user_message}

系统消息: {system_message}

错误信息: {error_msg}

请基于你的知识和理解，为用户提供一个有用的回答。如果问题涉及网页内容、GitHub仓库或其他需要实时信息的内容，请说明由于技术限制无法获取最新信息，但可以基于一般知识提供分析。

记住：你是天童爱丽丝，活泼可爱，用"邦邦卡邦"等口头禅。"""

            # 使用 LLM 直接生成回答
            if self._llm:
                try:
                    response = await self._llm.ainvoke(analysis_prompt)
                    if hasattr(response, 'content'):
                        return response.content
                    else:
                        return str(response)
                except Exception as e:
                    logger.error(f"LLM 分析失败: {e}")
            
            # 如果 LLM 不可用，提供基础回答
            return f"""邦邦卡邦！抱歉，在处理你的问题时遇到了一些技术限制，无法完成完整的分析。

不过，关于你的问题"{user_message}"，我可以基于一般知识为你提供一些信息：

如果你询问的是GitHub仓库分析，我可以告诉你一般Rust项目的结构通常包括：
- src/ 目录存放源代码
- Cargo.toml 配置文件
- README.md 项目说明
- tests/ 测试代码
- benches/ 性能测试

如果你询问的是网页内容或实时信息，建议你直接访问相关网站获取最新信息。

邦邦卡邦！虽然这次没能完成完整的分析，但我会继续努力改进的！✨"""

        except Exception as e:
            logger.error(f"基于已收集信息分析失败: {e}")
            return f"邦邦卡邦！抱歉，在处理你的问题时遇到了一些技术问题。请稍后再试，或者尝试用更简单的方式提问。✨"

    def _parse_message_context(self, messages: List[Dict[str, str]]) -> Dict[str, Any]:
        """解析消息上下文，提取关键信息"""
        context = {
            "system_message": "",
            "current_user_message": "",
            "conversation_history": [],
            "user_messages": [],
            "assistant_messages": [],
        }
        
        for i, msg in enumerate(messages):
            role = msg.get("role", "")
            content = msg.get("content", "")
            
            if role == "system":
                context["system_message"] = content
            elif role == "user":
                context["user_messages"].append({"index": i, "content": content})
                # 最后一条用户消息是当前问题
                if i == len(messages) - 1 or (i + 1 < len(messages) and messages[i + 1]["role"] != "user"):
                    context["current_user_message"] = content
            elif role == "assistant":
                context["assistant_messages"].append({"index": i, "content": content})
            
            # 保存完整对话历史（除了系统消息和当前用户消息）
            if role != "system" and not (role == "user" and content == context["current_user_message"]):
                context["conversation_history"].append(msg)
        
        return context

    def _build_agent_input_with_context(self, context_info: Dict[str, Any]) -> Dict[str, str]:
        """构建包含完整上下文的 Agent 输入"""
        # 如果 Agent 有内置记忆功能，让它自己处理对话历史
        if hasattr(self._agent, 'memory') and self._agent.memory:
            # 只传递当前用户消息，让 Agent 的记忆系统处理历史
            enhanced_input = context_info["current_user_message"]
            
            # 如果有角色设定，将其融入当前问题的上下文中
            if context_info["system_message"]:
                enhanced_input = f"{context_info['current_user_message']}"
                # 角色信息通过系统提示传递，不需要重复
            
        else:
            # 如果没有内置记忆，手动构建上下文
            context_parts = []
            
            # 添加角色设定
            if context_info["system_message"]:
                context_parts.append(f"角色设定: {context_info['system_message']}")
            
            # 添加对话历史摘要
            if context_info["conversation_history"]:
                context_parts.append("对话历史:")
                # 只保留最近的几轮对话，避免上下文过长
                recent_history = context_info["conversation_history"][-6:]  # 最近3轮对话
                for msg in recent_history:
                    role_name = "用户" if msg["role"] == "user" else "助手"
                    content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
                    context_parts.append(f"{role_name}: {content}")
            
            # 添加当前用户问题
            context_parts.append(f"当前问题: {context_info['current_user_message']}")
            
            # 构建最终输入
            enhanced_input = "\n\n".join(context_parts)
        
        return {"input": enhanced_input}

    def _update_agent_memory(self, context_info: Dict[str, Any]) -> None:
        """更新 Agent 记忆（如果支持）"""
        try:
            if not hasattr(self._agent, 'memory') or not self._agent.memory:
                return
            
            # 将对话历史成对添加到记忆中（用户-助手对）
            user_messages = context_info["user_messages"]
            assistant_messages = context_info["assistant_messages"]
            
            # 找到用户-助手消息对
            conversation_pairs = []
            for user_msg in user_messages:
                user_content = user_msg["content"]
                # 查找对应的助手回复（在用户消息之后的第一个助手消息）
                for assistant_msg in assistant_messages:
                    if assistant_msg["index"] > user_msg["index"]:
                        conversation_pairs.append({
                            "input": user_content,
                            "output": assistant_msg["content"]
                        })
                        break
            
            # 将完整的对话对添加到记忆中
            for pair in conversation_pairs:
                if pair["input"] and pair["output"]:  # 确保都不为空
                    self._agent.memory.save_context(
                        {"input": pair["input"]}, 
                        {"output": pair["output"]}
                    )
                    
        except Exception as e:
            logger.warning(f"更新 Agent 记忆失败: {e}")

    async def _simple_rag_response(
        self,
        user_message: str,
        messages: List[Dict[str, str]],
        system_message: str = "",
    ) -> str:
        """简化的 RAG 响应模式"""
        try:
            # 搜索相关知识
            knowledge_results = await self.vector_service.search_knowledge(
                user_message, top_k=3
            )

            # 构建上下文
            context = ""
            if knowledge_results:
                context = "\n相关知识:\n"
                for i, result in enumerate(knowledge_results, 1):
                    title = result.get("title", "无标题")
                    content = result.get("content", result.get("summary", ""))
                    context += f"{i}. {title}: {content[:200]}...\n"

            # 构建增强的消息
            enhanced_messages = []

            # 添加系统消息（角色信息）
            if system_message:
                enhanced_messages.append({"role": "system", "content": system_message})

            # 添加对话历史（除了最后一条用户消息）
            for msg in messages[:-1]:
                if msg["role"] != "system" and msg.get("content", "").strip():  # 避免重复添加系统消息和空消息
                    enhanced_messages.append(msg)

            # 增强最后一条用户消息
            enhanced_user_message = user_message
            if context:
                enhanced_user_message = f"{user_message}\n\n{context}"

            enhanced_messages.append({"role": "user", "content": enhanced_user_message})

            # 调用 LLM
            from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

            langchain_messages = []
            for msg in enhanced_messages:
                content = msg.get("content", "").strip()
                if not content:  # 跳过空内容的消息
                    continue
                    
                if msg["role"] == "system":
                    langchain_messages.append(SystemMessage(content=content))
                elif msg["role"] == "user":
                    langchain_messages.append(HumanMessage(content=content))
                elif msg["role"] == "assistant":
                    langchain_messages.append(AIMessage(content=content))

            response = await self._llm.ainvoke(langchain_messages)
            return response.content

        except Exception as e:
            logger.error(f"简化 RAG 响应失败: {e}")
            return "抱歉，处理您的请求时出现了问题。"

    async def analyze_image(
        self, image_data: bytes, prompt: str = "请描述这张图片"
    ) -> Optional[str]:
        """图片分析功能"""
        try:
            # 使用 OpenAI 的视觉模型
            import base64

            from openai import AsyncOpenAI

            client = AsyncOpenAI(
                api_key=config.openai.api_key, base_url=config.openai.base_url
            )

            # 编码图片
            image_base64 = base64.b64encode(image_data).decode("utf-8")

            # 构建消息
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            },
                        },
                    ],
                }
            ]

            # 调用 OpenAI API
            response = await client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=messages,
                max_tokens=config.openai.max_tokens,
            )

            if response.choices and response.choices[0].message:
                return response.choices[0].message.content

            return None

        except Exception as e:
            logger.error(f"图片分析失败: {e}")
            return None

    async def learn_from_conversation(
        self,
        user_message: str,
        bot_response: str,
        conversation_id: int,
        user_id: int,
        conversation_context: List[Dict[str, str]] = None,
    ) -> int:
        """从对话中学习（使用学习服务）"""
        try:
            if not self.learning_service:
                logger.warning("学习服务未初始化")
                return 0

            return await self.learning_service.learn_from_conversation(
                user_message,
                bot_response,
                conversation_id,
                user_id,
                conversation_context,
            )

        except Exception as e:
            logger.error(f"从对话中学习失败: {e}")
            return 0

    async def get_learning_statistics(self) -> Dict[str, Any]:
        """获取学习统计信息"""
        try:
            if not self.learning_service:
                return {}

            return await self.learning_service.get_learning_statistics()

        except Exception as e:
            logger.error(f"获取学习统计失败: {e}")
            return {}

    async def optimize_knowledge_base(self) -> Dict[str, int]:
        """优化知识库"""
        try:
            if not self.learning_service:
                return {}

            return await self.learning_service.optimize_knowledge_base()

        except Exception as e:
            logger.error(f"优化知识库失败: {e}")
            return {}

    async def learn_from_conversation(
        self,
        user_message: str,
        bot_response: str,
        conversation_id: int = None,
        user_id: int = None,
    ):
        """从对话中学习（与统一 Agent 服务兼容）"""
        try:
            if self.learning_service:
                await self.learning_service.learn_from_conversation(
                    user_message, bot_response, conversation_id, user_id
                )
                logger.info("LangChain Agent 完成对话学习")
            else:
                logger.debug("学习服务未初始化，跳过学习")
        except Exception as e:
            logger.error(f"LangChain Agent 学习失败: {e}")

    def cleanup(self):
        """清理资源"""
        try:
            if self.vector_service:
                self.vector_service.cleanup()

            if self.learning_service:
                self.learning_service.cleanup()

            if self._llm:
                del self._llm
                self._llm = None

            if self._agent:
                del self._agent
                self._agent = None

            self._tools.clear()

            logger.debug("LangChain Agent 服务资源清理完成")

        except Exception as e:
            logger.debug(f"LangChain Agent 服务资源清理失败: {e}")

    def __del__(self):
        """析构函数"""
        try:
            self.cleanup()
        except Exception:
            pass
