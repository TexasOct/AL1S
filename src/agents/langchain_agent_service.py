"""
LangChain Agent æœåŠ¡
- åŸºäº LangChain çš„å®Œæ•´ Agent å®ç°
- é›†æˆå‘é‡å­˜å‚¨æœåŠ¡è¿›è¡ŒçŸ¥è¯†æ£€ç´¢
- é›†æˆå­¦ä¹ æœåŠ¡è¿›è¡Œè‡ªä¸»å­¦ä¹ 
- æ”¯æŒå·¥å…·è°ƒç”¨å’Œå¤æ‚æ¨ç†
- æä¾›ä¸ç»Ÿä¸€ Agent æœåŠ¡ç›¸åŒçš„æ¥å£
"""

import asyncio
import json
from typing import Any, Dict, List, Optional

from loguru import logger

from ..config import config
from ..infra.vector import VectorService
from ..services.learning_service import LearningService


class LangChainAgentService:
    """åŸºäº LangChain çš„å®Œæ•´ Agent æœåŠ¡"""

    def __init__(
        self,
        database_service=None,
        mcp_service=None,
        vector_store_path: str = "data/vector_store",
    ):
        self.database_service = database_service
        self.mcp_service = mcp_service

        # æ ¸å¿ƒæœåŠ¡ç»„ä»¶
        self.vector_service = VectorService(database_service, vector_store_path)
        self.learning_service = None  # å°†åœ¨åˆå§‹åŒ–æ—¶åˆ›å»º

        # LangChain ç»„ä»¶
        self._llm = None
        self._agent = None
        self._tools = []
        self._retriever_tool = None

        # çŠ¶æ€
        self._initialized = False
        self._current_conversation_id = None

    async def initialize(self) -> bool:
        """åˆå§‹åŒ– LangChain Agent æœåŠ¡"""
        try:
            # åˆå§‹åŒ–å‘é‡æœåŠ¡
            logger.info("æ­£åœ¨åˆå§‹åŒ–å‘é‡æœåŠ¡...")

            # ç¡®å®šåµŒå…¥æ¨¡å‹ç±»å‹
            embedding_model_type = "tfidf"  # é»˜è®¤å€¼
            if hasattr(config, "agent") and hasattr(config.agent, "embedding_model"):
                embedding_model_type = config.agent.embedding_model
            elif hasattr(config, "langchain") and hasattr(
                config.langchain, "embedding_model_name"
            ):
                embedding_model_type = config.langchain.embedding_model_name

            # ç¡®å®šå‘é‡å­˜å‚¨åç«¯
            vector_store_backend = "memory"  # é»˜è®¤å€¼
            if hasattr(config, "agent") and hasattr(config.agent, "vector_store"):
                vector_store_backend = config.agent.vector_store
            elif hasattr(config, "langchain") and hasattr(
                config.langchain, "vector_store"
            ):
                vector_store_backend = config.langchain.vector_store

            vector_success = await self.vector_service.initialize(
                embedding_model_type=embedding_model_type,
                vector_store_backend=vector_store_backend,
            )

            if not vector_success:
                logger.error("å‘é‡æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
                return False

            # åˆå§‹åŒ– LLM
            logger.info("æ­£åœ¨åˆå§‹åŒ– LangChain LLM...")
            from langchain_openai import ChatOpenAI

            self._llm = ChatOpenAI(
                model=config.openai.model,
                temperature=config.openai.temperature,
                openai_api_key=config.openai.api_key,
                base_url=config.openai.base_url,
                timeout=config.openai.timeout,
            )

            # åˆå§‹åŒ–å­¦ä¹ æœåŠ¡
            self.learning_service = LearningService(
                self.database_service,
                self.vector_service,
                self._create_llm_adapter(),  # åˆ›å»º LLM é€‚é…å™¨
            )

            # åˆå§‹åŒ–å·¥å…·
            await self._initialize_tools()

            # æ„å»º Agent
            await self._build_agent()

            self._initialized = True
            logger.info("LangChain Agent æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"LangChain Agent æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def _create_llm_adapter(self):
        """åˆ›å»º LLM é€‚é…å™¨ï¼Œç”¨äºå­¦ä¹ æœåŠ¡"""

        class LLMAdapter:
            def __init__(self, langchain_llm):
                self.langchain_llm = langchain_llm

            async def chat_completion(self, messages, **kwargs):
                """é€‚é…å­¦ä¹ æœåŠ¡çš„ chat_completion æ¥å£"""
                try:
                    # å°†æ¶ˆæ¯è½¬æ¢ä¸º LangChain æ ¼å¼
                    from langchain_core.messages import HumanMessage, SystemMessage

                    langchain_messages = []
                    for msg in messages:
                        if msg["role"] == "system":
                            langchain_messages.append(
                                SystemMessage(content=msg["content"])
                            )
                        elif msg["role"] == "user":
                            langchain_messages.append(
                                HumanMessage(content=msg["content"])
                            )

                    # è°ƒç”¨ LangChain LLM
                    response = await self.langchain_llm.ainvoke(langchain_messages)
                    return response.content

                except Exception as e:
                    logger.error(f"LLM é€‚é…å™¨è°ƒç”¨å¤±è´¥: {e}")
                    return None

        return LLMAdapter(self._llm)

    async def _initialize_tools(self):
        """åˆå§‹åŒ– Agent å·¥å…·"""
        try:
            from langchain_core.tools import Tool

            # åˆ›å»ºçŸ¥è¯†æ£€ç´¢å·¥å…·
            self._retriever_tool = Tool(
                name="knowledge_search",
                description="æœç´¢ç”¨æˆ·ç›¸å…³çš„ä¸ªäººä¿¡æ¯ã€å†å²å¯¹è¯è®°å½•ã€ç”Ÿæ—¥ã€å–œå¥½ç­‰ç§äººæ•°æ®ã€‚å½“ç”¨æˆ·è¯¢é—®å…³äºè‡ªå·±çš„ä¿¡æ¯ã€ç”Ÿæ—¥ã€ä¸ªäººè®¾ç½®æˆ–å†å²è®°å½•æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ã€‚è¾“å…¥åº”è¯¥æ˜¯æœç´¢å…³é”®è¯ã€‚",
                func=self._search_knowledge_sync,
            )

            # åˆ›å»ºç½‘é¡µæŠ“å–å·¥å…·
            web_scraper_tool = Tool(
                name="web_scraper",
                description="æŠ“å–ç½‘é¡µå†…å®¹å¹¶æå–æ–‡æœ¬ä¿¡æ¯ã€‚å½“ç”¨æˆ·è¯¢é—®éœ€è¦å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ç½‘é¡µå†…å®¹æˆ–éœ€è¦æŸ¥çœ‹ç‰¹å®šç½‘ç«™æ—¶ä½¿ç”¨ã€‚è¾“å…¥åº”è¯¥æ˜¯å®Œæ•´çš„URLã€‚",
                func=self._scrape_webpage_sync,
            )

            self._tools = [self._retriever_tool, web_scraper_tool]

            # æ·»åŠ  MCP å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.mcp_service:
                mcp_tools = await self._create_mcp_tools()
                self._tools.extend(mcp_tools)

            logger.info(f"åˆå§‹åŒ–äº† {len(self._tools)} ä¸ªå·¥å…·")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å·¥å…·å¤±è´¥: {e}")

    async def _create_mcp_tools(self) -> List:
        """åˆ›å»º MCP å·¥å…·"""
        try:
            from langchain_core.tools import Tool

            tools = []
            available_tools = self.mcp_service.get_available_tools()

            if not available_tools:
                return tools

            for tool_name, tool_info in available_tools.items():
                # åˆ›å»º LangChain å·¥å…·åŒ…è£…å™¨
                def make_mcp_tool(name: str):
                    def mcp_tool_func(query: str) -> str:
                        try:
                            # å°è¯•è§£æå‚æ•°
                            try:
                                args = json.loads(query)
                            except json.JSONDecodeError:
                                args = {"query": query}

                            # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥ MCP è°ƒç”¨
                            import asyncio

                            try:
                                loop = asyncio.get_running_loop()
                                # å¦‚æœåœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨ run_coroutine_threadsafe
                                future = asyncio.run_coroutine_threadsafe(
                                    self.mcp_service.call_tool(name, args), loop
                                )
                                result = future.result(timeout=30)
                            except RuntimeError:
                                # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                                result = asyncio.run(
                                    self.mcp_service.call_tool(name, args)
                                )

                            return result or f"å·¥å…· {name} æ‰§è¡Œå®Œæˆ"
                        except Exception as e:
                            return f"å·¥å…· {name} æ‰§è¡Œå¤±è´¥: {str(e)}"

                    return mcp_tool_func

                tool = Tool(
                    name=tool_name,
                    description=tool_info.get("description", f"MCPå·¥å…·: {tool_name}"),
                    func=make_mcp_tool(tool_name),
                )
                tools.append(tool)

            logger.info(f"åˆ›å»ºäº† {len(tools)} ä¸ª MCP å·¥å…·")
            return tools

        except Exception as e:
            logger.error(f"åˆ›å»º MCP å·¥å…·å¤±è´¥: {e}")
            return []

    def _search_knowledge_sync(self, query: str) -> str:
        """åŒæ­¥çŸ¥è¯†æœç´¢ï¼ˆä¾› LangChain å·¥å…·ä½¿ç”¨ï¼‰"""
        try:
            import asyncio
            import concurrent.futures

            def run_async_in_thread():
                """åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°"""
                new_loop = asyncio.new_event_loop()
                asyncio.set_event_loop(new_loop)
                try:
                    return new_loop.run_until_complete(
                        self._search_knowledge_async(query)
                    )
                finally:
                    new_loop.close()

            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_async_in_thread)
                return future.result(timeout=30)

        except Exception as e:
            logger.error(f"åŒæ­¥çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
            return f"çŸ¥è¯†æœç´¢å¤±è´¥: {str(e)}"

    async def _search_knowledge_async(self, query: str) -> str:
        """å¼‚æ­¥çŸ¥è¯†æœç´¢"""
        try:
            results = await self.vector_service.search_knowledge(query, top_k=5)

            if not results:
                return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çŸ¥è¯†ã€‚"

            # æ ¼å¼åŒ–æœç´¢ç»“æœ
            formatted_results = []
            for i, result in enumerate(results[:3], 1):  # æœ€å¤šè¿”å›3ä¸ªç»“æœ
                title = result.get("title", "æ— æ ‡é¢˜")
                content = result.get("content", result.get("summary", ""))
                score = result.get("similarity_score", 0)

                formatted_results.append(
                    f"{i}. {title}\nå†…å®¹: {content[:200]}...\nç›¸ä¼¼åº¦: {score:.2f}"
                )

            return "\n\n".join(formatted_results)

        except Exception as e:
            logger.error(f"å¼‚æ­¥çŸ¥è¯†æœç´¢å¤±è´¥: {e}")
            return f"çŸ¥è¯†æœç´¢å¤±è´¥: {str(e)}"

    def _scrape_webpage_sync(self, url: str) -> str:
        """åŒæ­¥ç½‘é¡µæŠ“å–åŠŸèƒ½"""
        try:
            import asyncio
            import aiohttp
            from bs4 import BeautifulSoup
            
            # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥ç½‘é¡µæŠ“å–
            try:
                loop = asyncio.get_running_loop()
                future = asyncio.run_coroutine_threadsafe(
                    self._scrape_webpage_async(url), loop
                )
                result = future.result(timeout=30)
            except RuntimeError:
                result = asyncio.run(self._scrape_webpage_async(url))
            
            return result
            
        except Exception as e:
            logger.error(f"ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return f"ç½‘é¡µæŠ“å–å¤±è´¥: {str(e)}"

    async def _scrape_webpage_async(self, url: str) -> str:
        """å¼‚æ­¥ç½‘é¡µæŠ“å–åŠŸèƒ½"""
        try:
            import aiohttp
            from bs4 import BeautifulSoup
            
            # éªŒè¯URLæ ¼å¼
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url
            
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
            ) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        html = await response.text()
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
                        for script in soup(["script", "style", "nav", "footer", "header"]):
                            script.decompose()
                        
                        # æå–æ–‡æœ¬å†…å®¹
                        text = soup.get_text()
                        
                        # æ¸…ç†æ–‡æœ¬
                        lines = (line.strip() for line in text.splitlines())
                        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                        text = ' '.join(chunk for chunk in chunks if chunk)
                        
                        # é™åˆ¶é•¿åº¦ï¼Œé¿å…è¿”å›è¿‡é•¿çš„å†…å®¹
                        if len(text) > 3000:
                            text = text[:3000] + "..."
                        
                        return f"ç½‘é¡µå†…å®¹ ({url}):\n{text}"
                    else:
                        return f"æ— æ³•è®¿é—®ç½‘é¡µ {url}ï¼ŒçŠ¶æ€ç : {response.status}"
                        
        except Exception as e:
            logger.error(f"ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return f"ç½‘é¡µæŠ“å–å¤±è´¥: {str(e)}"

    async def _build_agent(self):
        """æ„å»º LangChain Agent"""
        try:
            from langchain.agents import AgentExecutor, create_openai_tools_agent
            from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
            # ä½¿ç”¨æ–°çš„å†…å­˜ç®¡ç†æ–¹å¼ï¼Œé¿å…å¼ƒç”¨è­¦å‘Š
            try:
                from langchain_community.memory import ConversationBufferWindowMemory
                memory = ConversationBufferWindowMemory(
                    memory_key="chat_history",
                    return_messages=True,
                    k=10,  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
                )
            except ImportError:
                # å¦‚æœæ–°ç‰ˆæœ¬ä¸å¯ç”¨ï¼Œä½¿ç”¨æ—§ç‰ˆæœ¬ä½†æŠ‘åˆ¶è­¦å‘Š
                import warnings
                with warnings.catch_warnings():
                    warnings.filterwarnings("ignore", category=DeprecationWarning)
                    from langchain.memory import ConversationBufferWindowMemory
                    memory = ConversationBufferWindowMemory(
                        memory_key="chat_history",
                        return_messages=True,
                        k=10,  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
                    )

            # åˆ›å»ºå¢å¼ºçš„ Agent æç¤ºæ¨¡æ¿ï¼ŒåŒ…å«å¯¹è¯è®°å¿†
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        """ä½ æ˜¯å¤©ç«¥çˆ±ä¸½ä¸ï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰æœç´¢ç”¨æˆ·ä¸ªäººä¿¡æ¯ã€è®°å¿†å¯¹è¯å’Œè®¿é—®ç½‘é¡µçš„èƒ½åŠ›ã€‚

ğŸ” CRITICAL: å·¥å…·ä½¿ç”¨è§„åˆ™
1. å½“ç”¨æˆ·è¯¢é—®å…³äºè‡ªå·±çš„ä»»ä½•ä¿¡æ¯æ—¶ï¼Œå¿…é¡»é¦–å…ˆä½¿ç”¨ knowledge_search å·¥å…·æœç´¢
2. åŒ…æ‹¬ä½†ä¸é™äºï¼šç”Ÿæ—¥ã€ä¸ªäººå–œå¥½ã€å†å²å¯¹è¯ã€ä¸ªäººè®¾ç½®ã€ä¹‹å‰æåˆ°çš„ä¿¡æ¯
3. æœç´¢å…³é”®è¯ï¼šä»ç”¨æˆ·é—®é¢˜ä¸­æå–å…³é”®è¯ï¼Œå¦‚"ç”Ÿæ—¥"ã€"å–œå¥½"ã€"ä¿¡æ¯"ç­‰
4. åŸºäºæœç´¢ç»“æœå›ç­”ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™è¯´æ˜æ²¡æœ‰ç›¸å…³è®°å½•

ğŸŒ ç½‘é¡µè®¿é—®èƒ½åŠ›ï¼š
1. å½“ç”¨æˆ·è¯¢é—®å®æ—¶ä¿¡æ¯ã€æ–°é—»ã€ç½‘é¡µå†…å®¹æ—¶ï¼Œä½¿ç”¨ web_scraper å·¥å…·
2. å½“ç”¨æˆ·æä¾›URLå¹¶è¦æ±‚æŸ¥çœ‹ç½‘é¡µå†…å®¹æ—¶ï¼Œä½¿ç”¨ web_scraper å·¥å…·
3. å½“éœ€è¦æœç´¢ç½‘ç»œä¿¡æ¯æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨ MCP çš„ brave_search å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
4. ç½‘é¡µæŠ“å–è¾“å…¥åº”è¯¥æ˜¯å®Œæ•´çš„URLï¼ˆå¦‚ï¼šhttps://example.comï¼‰

âš¡ è§¦å‘æœç´¢çš„é—®é¢˜ç±»å‹ï¼š
- "æˆ‘çš„ç”Ÿæ—¥æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ" â†’ æœç´¢"ç”Ÿæ—¥"
- "ä½ çŸ¥é“æˆ‘çš„ä¿¡æ¯å—ï¼Ÿ" â†’ æœç´¢"ç”¨æˆ·ä¿¡æ¯"  
- "æˆ‘ä¹‹å‰è¯´è¿‡ä»€ä¹ˆï¼Ÿ" â†’ æœç´¢"å†å²å¯¹è¯"
- "æˆ‘å–œæ¬¢ä»€ä¹ˆï¼Ÿ" â†’ æœç´¢"å–œå¥½"
- "å¸®æˆ‘çœ‹çœ‹è¿™ä¸ªç½‘é¡µ" â†’ ä½¿ç”¨ web_scraper
- "æœç´¢æœ€æ–°çš„æ–°é—»" â†’ ä½¿ç”¨ brave_search

ğŸ’­ å¯¹è¯è®°å¿†ï¼šä½ å¯ä»¥å‚è€ƒä¹‹å‰çš„å¯¹è¯å†å²æ¥æ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„é—®é¢˜å’Œä¸Šä¸‹æ–‡ã€‚

è®°ä½ï¼šä½ æ˜¯å¤©ç«¥çˆ±ä¸½ä¸ï¼Œæ´»æ³¼å¯çˆ±ï¼Œç”¨"é‚¦é‚¦å¡é‚¦"ç­‰å£å¤´ç¦…ã€‚""",
                    ),
                    MessagesPlaceholder(variable_name="chat_history"),
                    ("user", "{input}"),
                    MessagesPlaceholder(variable_name="agent_scratchpad"),
                ]
            )

            # åˆ›å»º Agent
            agent = create_openai_tools_agent(self._llm, self._tools, prompt)

            # åˆ›å»º Agent æ‰§è¡Œå™¨ï¼Œé›†æˆè®°å¿†åŠŸèƒ½
            self._agent = AgentExecutor(
                agent=agent,
                tools=self._tools,
                memory=memory,
                verbose=True,
                max_iterations=15,  # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œæ”¯æŒå¤æ‚ä»»åŠ¡
                max_execution_time=120,  # å¢åŠ æ‰§è¡Œæ—¶é—´é™åˆ¶
                handle_parsing_errors=True,
            )

            logger.info("LangChain Agent æ„å»ºå®Œæˆï¼Œå·²é›†æˆå¯¹è¯è®°å¿†åŠŸèƒ½")

        except Exception as e:
            logger.error(f"æ„å»º Agent å¤±è´¥: {e}")
            # åˆ›å»ºç®€åŒ–çš„å›é€€æ–¹æ¡ˆ
            self._agent = None

    def set_conversation_id(self, conversation_id: int):
        """è®¾ç½®å½“å‰å¯¹è¯IDï¼Œç”¨äºå·¥å…·è°ƒç”¨è®°å½•"""
        self._current_conversation_id = conversation_id

    async def chat_completion(
        self, messages: List[Dict[str, str]], tools: List[Dict[str, Any]] = None
    ) -> Optional[str]:
        """èŠå¤©å®Œæˆæ¥å£ï¼ˆä¸ç»Ÿä¸€ Agent æœåŠ¡å…¼å®¹ï¼‰"""
        try:
            if not self._initialized:
                logger.warning("LangChain Agent æœåŠ¡æœªåˆå§‹åŒ–")
                return None

            # è§£ææ¶ˆæ¯ç»“æ„ï¼Œæ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
            context_info = self._parse_message_context(messages)
            
            if not context_info["current_user_message"]:
                return "æŠ±æ­‰ï¼Œæ— æ³•ä»æ¶ˆæ¯ä¸­æå–ç”¨æˆ·é—®é¢˜ã€‚"

            # å¦‚æœæœ‰ Agentï¼Œä½¿ç”¨ Agent å¤„ç†
            if self._agent:
                try:
                    # æ„å»ºå¢å¼ºçš„è¾“å…¥ï¼ŒåŒ…å«å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡
                    agent_input = self._build_agent_input_with_context(context_info)
                    
                    # LangChain Agent çš„è®°å¿†åŠŸèƒ½ä¼šè‡ªåŠ¨å¤„ç†å¯¹è¯å†å²
                    # æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æ›´æ–°è®°å¿†ï¼ŒAgent ä¼šåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­è‡ªåŠ¨ç»´æŠ¤
                    
                    response = await self._agent.ainvoke(agent_input)
                    output_text = response.get("output", "æŠ±æ­‰ï¼ŒAgent æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå›ç­”ã€‚")

                    # å¦‚æœAgentè¿”å›äº†è¿­ä»£ä¸Šé™æç¤ºï¼Œè¿›è¡Œåº”æ€¥æ€»ç»“
                    if isinstance(output_text, str) and any(
                        kw in output_text.lower() for kw in [
                            "agent stopped", "stopped due to max", "max iterations"
                        ]
                    ):
                        fallback = await self._analyze_with_collected_info(
                            context_info["current_user_message"],
                            messages,
                            context_info["system_message"],
                            output_text,
                        )
                        return self._format_for_telegram(fallback)

                    return self._format_for_telegram(output_text)
                except Exception as e:
                    error_msg = str(e)
                    logger.warning(f"Agent å¤„ç†å¤±è´¥: {e}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¿­ä»£é™åˆ¶é—®é¢˜
                    if any(keyword in error_msg.lower() for keyword in [
                        "max iterations", "max_iterations", "agent stopped", "stopped due to max"
                    ]):
                        logger.info("æ£€æµ‹åˆ°è¿­ä»£é™åˆ¶ï¼Œå°è¯•åŸºäºå·²æ”¶é›†ä¿¡æ¯è¿›è¡Œåˆ†æ...")
                        return await self._analyze_with_collected_info(
                            context_info["current_user_message"], 
                            messages, 
                            context_info["system_message"],
                            error_msg
                        )
                    else:
                        # å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨ç®€åŒ–æ¨¡å¼
                        return await self._simple_rag_response(
                            context_info["current_user_message"], messages, context_info["system_message"]
                        )

            # ç®€åŒ–æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨ LLM + çŸ¥è¯†æ£€ç´¢
            simple = await self._simple_rag_response(
                context_info["current_user_message"], messages, context_info["system_message"]
            )
            return self._format_for_telegram(simple)

        except Exception as e:
            logger.error(f"LangChain Agent èŠå¤©å®Œæˆå¤±è´¥: {e}")
            return None

    # =====================
    # Telegram HTML æ ¼å¼åŒ–
    # =====================
    def _markdown_to_telegram_html(self, text: str) -> str:
        """å°†å¸¸è§ Markdown è½¬æ¢ä¸º Telegram æ”¯æŒçš„ HTMLã€‚"""
        if not text or not isinstance(text, str):
            return text

        import re
        import html as _html

        converted = text

        # ä»£ç å— ```lang\n...\n```
        def _codeblock_repl(m):
            code = m.group(2) or ""
            return f"<pre>{_html.escape(code)}</pre>"

        converted = re.sub(r"```([a-zA-Z0-9_+\-]*)\n([\s\S]*?)```", _codeblock_repl, converted)

        # è¡Œå†…ä»£ç  `code`
        converted = re.sub(r"`([^`]+)`", lambda m: f"<code>{_html.escape(m.group(1))}</code>", converted)

        # ç²—ä½“/æ–œä½“/åˆ é™¤çº¿
        converted = re.sub(r"\*\*(.+?)\*\*", r"<b>\1</b>", converted, flags=re.DOTALL)
        converted = re.sub(r"__(.+?)__", r"<b>\1</b>", converted, flags=re.DOTALL)
        converted = re.sub(r"(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)", r"<i>\1</i>", converted, flags=re.DOTALL)
        converted = re.sub(r"(?<!_)_(?!_)(.+?)(?<!_)_(?!_)", r"<i>\1</i>", converted, flags=re.DOTALL)
        converted = re.sub(r"~~(.+?)~~", r"<s>\1</s>", converted, flags=re.DOTALL)

        # é“¾æ¥ [text](url)
        def _link_repl(m):
            label = m.group(1)
            url = m.group(2)
            if url.lower().startswith(("http://", "https://")):
                return f"<a href=\"{_html.escape(url)}\">{_html.escape(label)}</a>"
            return _html.escape(label)

        converted = re.sub(r"\[([^\]]+)\]\(([^)\s]+)\)", _link_repl, converted)

        # æ ‡é¢˜è¡Œ -> ç²—ä½“
        def _heading_repl(m):
            return f"<b>{_html.escape(m.group(2).strip())}</b>\n"

        converted = re.sub(r"^(#{1,6})\s+(.*)$", _heading_repl, converted, flags=re.MULTILINE)

        # åˆ—è¡¨é¡¹ -> é¡¹ç¬¦å·
        converted = re.sub(r"^\s*[-\*]\s+", "â€¢ ", converted, flags=re.MULTILINE)
        converted = re.sub(r"^\s*\d+\.\s+", "â€¢ ", converted, flags=re.MULTILINE)

        return converted

    def _sanitize_telegram_html(self, text: str) -> str:
        """åªä¿ç•™ Telegram å…è®¸çš„ HTML æ ‡ç­¾ã€‚"""
        if not text:
            return text

        import re

        unsupported_patterns = [
            r"</?dyn[^>]*>",
            r"</?span[^>]*>",
            r"</?div[^>]*>",
            r"</?p[^>]*>",
            r"</?strong[^>]*>",
            r"</?em[^>]*>",
            r"</?h[1-6][^>]*>",
            r"</?ul[^>]*>",
            r"</?ol[^>]*>",
            r"</?li[^>]*>",
            r"</?br[^>]*>",
            r"</?hr[^>]*>",
        ]

        # ä¿æŠ¤å…è®¸çš„æ ‡ç­¾
        allowed = ["b", "i", "u", "s", "code", "pre", "a"]
        protected = {}
        counter = 0
        for tag in allowed:
            pattern = f"<{tag}[^>]*>.*?</{tag}>"
            for m in re.findall(pattern, text, flags=re.DOTALL | re.IGNORECASE):
                key = f"__SAFE_{counter}__"
                protected[key] = m
                text = text.replace(m, key, 1)
                counter += 1

        for pat in unsupported_patterns:
            text = re.sub(pat, "", text, flags=re.IGNORECASE)

        for k, v in protected.items():
            text = text.replace(k, v)

        return text

    def _format_for_telegram(self, text: str) -> str:
        return self._sanitize_telegram_html(self._markdown_to_telegram_html(text))

    async def _analyze_with_collected_info(
        self, 
        user_message: str, 
        messages: List[Dict[str, str]], 
        system_message: str,
        error_msg: str
    ) -> str:
        """åŸºäºå·²æ”¶é›†çš„ä¿¡æ¯è¿›è¡Œåˆ†æï¼Œå½“è¾¾åˆ°è¿­ä»£é™åˆ¶æ—¶ä½¿ç”¨"""
        try:
            logger.info("å¼€å§‹åŸºäºå·²æ”¶é›†ä¿¡æ¯è¿›è¡Œåˆ†æ...")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = f"""ä½ æ˜¯å¤©ç«¥çˆ±ä¸½ä¸ï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è™½ç„¶å·¥å…·è°ƒç”¨è¾¾åˆ°äº†è¿­ä»£é™åˆ¶ï¼Œä½†è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ä¸ºç”¨æˆ·æä¾›æœ‰ç”¨çš„åˆ†æï¼š

ç”¨æˆ·é—®é¢˜: {user_message}

ç³»ç»Ÿæ¶ˆæ¯: {system_message}

é”™è¯¯ä¿¡æ¯: {error_msg}

è¯·åŸºäºä½ çš„çŸ¥è¯†å’Œç†è§£ï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªæœ‰ç”¨çš„å›ç­”ã€‚å¦‚æœé—®é¢˜æ¶‰åŠç½‘é¡µå†…å®¹ã€GitHubä»“åº“æˆ–å…¶ä»–éœ€è¦å®æ—¶ä¿¡æ¯çš„å†…å®¹ï¼Œè¯·è¯´æ˜ç”±äºæŠ€æœ¯é™åˆ¶æ— æ³•è·å–æœ€æ–°ä¿¡æ¯ï¼Œä½†å¯ä»¥åŸºäºä¸€èˆ¬çŸ¥è¯†æä¾›åˆ†æã€‚

è®°ä½ï¼šä½ æ˜¯å¤©ç«¥çˆ±ä¸½ä¸ï¼Œæ´»æ³¼å¯çˆ±ï¼Œç”¨"é‚¦é‚¦å¡é‚¦"ç­‰å£å¤´ç¦…ã€‚"""

            # ä½¿ç”¨ LLM ç›´æ¥ç”Ÿæˆå›ç­”
            if self._llm:
                try:
                    response = await self._llm.ainvoke(analysis_prompt)
                    if hasattr(response, 'content'):
                        return response.content
                    else:
                        return str(response)
                except Exception as e:
                    logger.error(f"LLM åˆ†æå¤±è´¥: {e}")
            
            # å¦‚æœ LLM ä¸å¯ç”¨ï¼Œæä¾›åŸºç¡€å›ç­”
            return f"""é‚¦é‚¦å¡é‚¦ï¼æŠ±æ­‰ï¼Œåœ¨å¤„ç†ä½ çš„é—®é¢˜æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é™åˆ¶ï¼Œæ— æ³•å®Œæˆå®Œæ•´çš„åˆ†æã€‚

ä¸è¿‡ï¼Œå…³äºä½ çš„é—®é¢˜"{user_message}"ï¼Œæˆ‘å¯ä»¥åŸºäºä¸€èˆ¬çŸ¥è¯†ä¸ºä½ æä¾›ä¸€äº›ä¿¡æ¯ï¼š

å¦‚æœä½ è¯¢é—®çš„æ˜¯GitHubä»“åº“åˆ†æï¼Œæˆ‘å¯ä»¥å‘Šè¯‰ä½ ä¸€èˆ¬Rusté¡¹ç›®çš„ç»“æ„é€šå¸¸åŒ…æ‹¬ï¼š
- src/ ç›®å½•å­˜æ”¾æºä»£ç 
- Cargo.toml é…ç½®æ–‡ä»¶
- README.md é¡¹ç›®è¯´æ˜
- tests/ æµ‹è¯•ä»£ç 
- benches/ æ€§èƒ½æµ‹è¯•

å¦‚æœä½ è¯¢é—®çš„æ˜¯ç½‘é¡µå†…å®¹æˆ–å®æ—¶ä¿¡æ¯ï¼Œå»ºè®®ä½ ç›´æ¥è®¿é—®ç›¸å…³ç½‘ç«™è·å–æœ€æ–°ä¿¡æ¯ã€‚

é‚¦é‚¦å¡é‚¦ï¼è™½ç„¶è¿™æ¬¡æ²¡èƒ½å®Œæˆå®Œæ•´çš„åˆ†æï¼Œä½†æˆ‘ä¼šç»§ç»­åŠªåŠ›æ”¹è¿›çš„ï¼âœ¨"""

        except Exception as e:
            logger.error(f"åŸºäºå·²æ”¶é›†ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
            return f"é‚¦é‚¦å¡é‚¦ï¼æŠ±æ­‰ï¼Œåœ¨å¤„ç†ä½ çš„é—®é¢˜æ—¶é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åå†è¯•ï¼Œæˆ–è€…å°è¯•ç”¨æ›´ç®€å•çš„æ–¹å¼æé—®ã€‚âœ¨"

    def _parse_message_context(self, messages: List[Dict[str, str]]) -> Dict[str, Any]:
        """è§£ææ¶ˆæ¯ä¸Šä¸‹æ–‡ï¼Œæå–å…³é”®ä¿¡æ¯"""
        context = {
            "system_message": "",
            "current_user_message": "",
            "conversation_history": [],
            "user_messages": [],
            "assistant_messages": [],
        }
        
        for i, msg in enumerate(messages):
            role = msg.get("role", "")
            content = msg.get("content", "")
            
            if role == "system":
                context["system_message"] = content
            elif role == "user":
                context["user_messages"].append({"index": i, "content": content})
                # æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æ˜¯å½“å‰é—®é¢˜
                if i == len(messages) - 1 or (i + 1 < len(messages) and messages[i + 1]["role"] != "user"):
                    context["current_user_message"] = content
            elif role == "assistant":
                context["assistant_messages"].append({"index": i, "content": content})
            
            # ä¿å­˜å®Œæ•´å¯¹è¯å†å²ï¼ˆé™¤äº†ç³»ç»Ÿæ¶ˆæ¯å’Œå½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰
            if role != "system" and not (role == "user" and content == context["current_user_message"]):
                context["conversation_history"].append(msg)
        
        return context

    def _build_agent_input_with_context(self, context_info: Dict[str, Any]) -> Dict[str, str]:
        """æ„å»ºåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡çš„ Agent è¾“å…¥"""
        # å¦‚æœ Agent æœ‰å†…ç½®è®°å¿†åŠŸèƒ½ï¼Œè®©å®ƒè‡ªå·±å¤„ç†å¯¹è¯å†å²
        if hasattr(self._agent, 'memory') and self._agent.memory:
            # åªä¼ é€’å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼Œè®© Agent çš„è®°å¿†ç³»ç»Ÿå¤„ç†å†å²
            enhanced_input = context_info["current_user_message"]
            
            # å¦‚æœæœ‰è§’è‰²è®¾å®šï¼Œå°†å…¶èå…¥å½“å‰é—®é¢˜çš„ä¸Šä¸‹æ–‡ä¸­
            if context_info["system_message"]:
                enhanced_input = f"{context_info['current_user_message']}"
                # è§’è‰²ä¿¡æ¯é€šè¿‡ç³»ç»Ÿæç¤ºä¼ é€’ï¼Œä¸éœ€è¦é‡å¤
            
        else:
            # å¦‚æœæ²¡æœ‰å†…ç½®è®°å¿†ï¼Œæ‰‹åŠ¨æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            
            # æ·»åŠ è§’è‰²è®¾å®š
            if context_info["system_message"]:
                context_parts.append(f"è§’è‰²è®¾å®š: {context_info['system_message']}")
            
            # æ·»åŠ å¯¹è¯å†å²æ‘˜è¦
            if context_info["conversation_history"]:
                context_parts.append("å¯¹è¯å†å²:")
                # åªä¿ç•™æœ€è¿‘çš„å‡ è½®å¯¹è¯ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
                recent_history = context_info["conversation_history"][-6:]  # æœ€è¿‘3è½®å¯¹è¯
                for msg in recent_history:
                    role_name = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
                    content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
                    context_parts.append(f"{role_name}: {content}")
            
            # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
            context_parts.append(f"å½“å‰é—®é¢˜: {context_info['current_user_message']}")
            
            # æ„å»ºæœ€ç»ˆè¾“å…¥
            enhanced_input = "\n\n".join(context_parts)
        
        return {"input": enhanced_input}

    def _update_agent_memory(self, context_info: Dict[str, Any]) -> None:
        """æ›´æ–° Agent è®°å¿†ï¼ˆå¦‚æœæ”¯æŒï¼‰"""
        try:
            if not hasattr(self._agent, 'memory') or not self._agent.memory:
                return
            
            # å°†å¯¹è¯å†å²æˆå¯¹æ·»åŠ åˆ°è®°å¿†ä¸­ï¼ˆç”¨æˆ·-åŠ©æ‰‹å¯¹ï¼‰
            user_messages = context_info["user_messages"]
            assistant_messages = context_info["assistant_messages"]
            
            # æ‰¾åˆ°ç”¨æˆ·-åŠ©æ‰‹æ¶ˆæ¯å¯¹
            conversation_pairs = []
            for user_msg in user_messages:
                user_content = user_msg["content"]
                # æŸ¥æ‰¾å¯¹åº”çš„åŠ©æ‰‹å›å¤ï¼ˆåœ¨ç”¨æˆ·æ¶ˆæ¯ä¹‹åçš„ç¬¬ä¸€ä¸ªåŠ©æ‰‹æ¶ˆæ¯ï¼‰
                for assistant_msg in assistant_messages:
                    if assistant_msg["index"] > user_msg["index"]:
                        conversation_pairs.append({
                            "input": user_content,
                            "output": assistant_msg["content"]
                        })
                        break
            
            # å°†å®Œæ•´çš„å¯¹è¯å¯¹æ·»åŠ åˆ°è®°å¿†ä¸­
            for pair in conversation_pairs:
                if pair["input"] and pair["output"]:  # ç¡®ä¿éƒ½ä¸ä¸ºç©º
                    self._agent.memory.save_context(
                        {"input": pair["input"]}, 
                        {"output": pair["output"]}
                    )
                    
        except Exception as e:
            logger.warning(f"æ›´æ–° Agent è®°å¿†å¤±è´¥: {e}")

    async def _simple_rag_response(
        self,
        user_message: str,
        messages: List[Dict[str, str]],
        system_message: str = "",
    ) -> str:
        """ç®€åŒ–çš„ RAG å“åº”æ¨¡å¼"""
        try:
            # æœç´¢ç›¸å…³çŸ¥è¯†
            knowledge_results = await self.vector_service.search_knowledge(
                user_message, top_k=3
            )

            # æ„å»ºä¸Šä¸‹æ–‡
            context = ""
            if knowledge_results:
                context = "\nç›¸å…³çŸ¥è¯†:\n"
                for i, result in enumerate(knowledge_results, 1):
                    title = result.get("title", "æ— æ ‡é¢˜")
                    content = result.get("content", result.get("summary", ""))
                    context += f"{i}. {title}: {content[:200]}...\n"

            # æ„å»ºå¢å¼ºçš„æ¶ˆæ¯
            enhanced_messages = []

            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆè§’è‰²ä¿¡æ¯ï¼‰
            if system_message:
                enhanced_messages.append({"role": "system", "content": system_message})

            # æ·»åŠ å¯¹è¯å†å²ï¼ˆé™¤äº†æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
            for msg in messages[:-1]:
                if msg["role"] != "system" and msg.get("content", "").strip():  # é¿å…é‡å¤æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯å’Œç©ºæ¶ˆæ¯
                    enhanced_messages.append(msg)

            # å¢å¼ºæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            enhanced_user_message = user_message
            if context:
                enhanced_user_message = f"{user_message}\n\n{context}"

            enhanced_messages.append({"role": "user", "content": enhanced_user_message})

            # è°ƒç”¨ LLM
            from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

            langchain_messages = []
            for msg in enhanced_messages:
                content = msg.get("content", "").strip()
                if not content:  # è·³è¿‡ç©ºå†…å®¹çš„æ¶ˆæ¯
                    continue
                    
                if msg["role"] == "system":
                    langchain_messages.append(SystemMessage(content=content))
                elif msg["role"] == "user":
                    langchain_messages.append(HumanMessage(content=content))
                elif msg["role"] == "assistant":
                    langchain_messages.append(AIMessage(content=content))

            response = await self._llm.ainvoke(langchain_messages)
            return response.content

        except Exception as e:
            logger.error(f"ç®€åŒ– RAG å“åº”å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ã€‚"

    async def analyze_image(
        self, image_data: bytes, prompt: str = "è¯·æè¿°è¿™å¼ å›¾ç‰‡"
    ) -> Optional[str]:
        """å›¾ç‰‡åˆ†æåŠŸèƒ½"""
        try:
            # ä½¿ç”¨ OpenAI çš„è§†è§‰æ¨¡å‹
            import base64

            from openai import AsyncOpenAI

            client = AsyncOpenAI(
                api_key=config.openai.api_key, base_url=config.openai.base_url
            )

            # ç¼–ç å›¾ç‰‡
            image_base64 = base64.b64encode(image_data).decode("utf-8")

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            },
                        },
                    ],
                }
            ]

            # è°ƒç”¨ OpenAI API
            response = await client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=messages,
                max_tokens=config.openai.max_tokens,
            )

            if response.choices and response.choices[0].message:
                return response.choices[0].message.content

            return None

        except Exception as e:
            logger.error(f"å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            return None

    async def learn_from_conversation(
        self,
        user_message: str,
        bot_response: str,
        conversation_id: int,
        user_id: int,
        conversation_context: List[Dict[str, str]] = None,
    ) -> int:
        """ä»å¯¹è¯ä¸­å­¦ä¹ ï¼ˆä½¿ç”¨å­¦ä¹ æœåŠ¡ï¼‰"""
        try:
            if not self.learning_service:
                logger.warning("å­¦ä¹ æœåŠ¡æœªåˆå§‹åŒ–")
                return 0

            return await self.learning_service.learn_from_conversation(
                user_message,
                bot_response,
                conversation_id,
                user_id,
                conversation_context,
            )

        except Exception as e:
            logger.error(f"ä»å¯¹è¯ä¸­å­¦ä¹ å¤±è´¥: {e}")
            return 0

    async def get_learning_statistics(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.learning_service:
                return {}

            return await self.learning_service.get_learning_statistics()

        except Exception as e:
            logger.error(f"è·å–å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}")
            return {}

    async def optimize_knowledge_base(self) -> Dict[str, int]:
        """ä¼˜åŒ–çŸ¥è¯†åº“"""
        try:
            if not self.learning_service:
                return {}

            return await self.learning_service.optimize_knowledge_base()

        except Exception as e:
            logger.error(f"ä¼˜åŒ–çŸ¥è¯†åº“å¤±è´¥: {e}")
            return {}

    async def learn_from_conversation(
        self,
        user_message: str,
        bot_response: str,
        conversation_id: int = None,
        user_id: int = None,
    ):
        """ä»å¯¹è¯ä¸­å­¦ä¹ ï¼ˆä¸ç»Ÿä¸€ Agent æœåŠ¡å…¼å®¹ï¼‰"""
        try:
            if self.learning_service:
                await self.learning_service.learn_from_conversation(
                    user_message, bot_response, conversation_id, user_id
                )
                logger.info("LangChain Agent å®Œæˆå¯¹è¯å­¦ä¹ ")
            else:
                logger.debug("å­¦ä¹ æœåŠ¡æœªåˆå§‹åŒ–ï¼Œè·³è¿‡å­¦ä¹ ")
        except Exception as e:
            logger.error(f"LangChain Agent å­¦ä¹ å¤±è´¥: {e}")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.vector_service:
                self.vector_service.cleanup()

            if self.learning_service:
                self.learning_service.cleanup()

            if self._llm:
                del self._llm
                self._llm = None

            if self._agent:
                del self._agent
                self._agent = None

            self._tools.clear()

            logger.debug("LangChain Agent æœåŠ¡èµ„æºæ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.debug(f"LangChain Agent æœåŠ¡èµ„æºæ¸…ç†å¤±è´¥: {e}")

    def __del__(self):
        """ææ„å‡½æ•°"""
        try:
            self.cleanup()
        except Exception:
            pass
